# CMCN
This is the code and data for our paper：“Chinese Medical Concept Normalization Using Continual Learning and Knowledge-Enhanced” This research involves three tasks altogether, and the code used in each task has been given the corresponding web disk link.

# Requirements
We have a requirements.txt file in each code download link, which allows you to run the following code after downloading：<br>
    pip install -r requirements.txt

# Basic experiment
The code for thirteen basic model experiments is published

CNN Link: https://pan.quark.cn/s/3938563c1667 Extract code: h4GK

CNN+AT Link: https://pan.quark.cn/s/d41c212c0a0a Extract code: LwG1

GRU Link：https://pan.quark.cn/s/506237a235d0 Extract code：RK35

GRU+AT Link：https://pan.quark.cn/s/506237a235d0 Extract code：RK35

LINUXS Link：https://pan.quark.cn/s/2a867f2a1206 Extract code：sjJt

LSTM Link：https://pan.quark.cn/s/6771c6d38117 Extract code：DLtK

LSTM+AT Link：https://pan.quark.cn/s/45f467b258f2 Extract code：VaYT

Random quantifier Link：https://pan.quark.cn/s/670edac70f0a Extract code：gARi

Random vector word Link：https://pan.quark.cn/s/93ee5414f08a Extract code：NfzE

External semantic feature Link：https://pan.quark.cn/s/3e60eb5ab8a0 Extract code：qFns

Vector combination experiment Link：https://pan.quark.cn/s/a857ded18043 Extract code：fgXm

English random vector Link：https://pan.quark.cn/s/2a1e30e3cbd1 Extract code：q5aX

# Multi-tasking, BERT, hybrid neural networks
Below are some model experiments of multi-tasking, bert, and hybrid neural networks

BERT_sentence Link：https://pan.quark.cn/s/a7b4c072a126 Extract code：q2MC

BERT_X_CNN Link：https://pan.quark.cn/s/f58801aa05ee Extract code：x2Bq

BERT_word Link：https://pan.quark.cn/s/c201c413ecd4 Extract code：uZKA

BiGRU_CNN Link：https://pan.quark.cn/s/3a2ac226967c Extract code：iDBG

BiLSTM_CNN Link：https://pan.quark.cn/s/a869a9b53f63 Extract code：uSMU

chinese_L-12_H-768_A-12 Link：https://pan.quark.cn/s/3b93a0e4fa8a Extract code：JnZA

Multi_task_CNN_BERT(Both with and without auxiliary tasks) Link：https://pan.quark.cn/s/a8b4b617e4af Extract code：JT6j

# Continuous learning experiment
Here are some experiments for continuous learning

1_dict_dynamic Link：https://pan.quark.cn/s/f22ae5fe7c38 Extract code：9F4R

Part-of-speech experimental isolation Link：https://pan.quark.cn/s/899059ebca2a Extract code：aqTL

dynamic_bert(BERT led continuous learning) Link：https://pan.quark.cn/s/73fe8bbd2c38 Extract code：RjJT

dynamic_GCNN(GCNN led continuous learning) Link：https://pan.quark.cn/s/a395af85345a Extract code：LuMz

E_x_fuse(Power function continuous learning) Link：https://pan.quark.cn/s/fa4f149d9783 Extract code：aK5i

Ln_fuse(Logarithmic functions continue to learn）Link：https://pan.quark.cn/s/022827b3a7e4 Extract code：iTxc

n_AND_ICD10（An optimal model combining parts of speech and dictionaries）Link：https://pan.quark.cn/s/4ce27d8c4331 Extract code：DBUB

PartOfSpeech_a Link：https://pan.quark.cn/s/117296aa7442 Extract code：LzDB

PartOfSpeech_d Link：https://pan.quark.cn/s/21ef8ffbd83c Extract code：mWgZ

PartOfSpeech_n Link：https://pan.quark.cn/s/5b23640a30f8 Extract code：Ai83

PartOfSpeech_v Link：https://pan.quark.cn/s/32d36fd4c1ae Extract code：Vz7i
